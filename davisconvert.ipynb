{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, CuDNNLSTM, BatchNormalization, Bidirectional, Reshape, TimeDistributed\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "from keras import backend as K\n",
    "from pymms.sdc import mrmms_sdc_api as mms\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "import datetime as dt\n",
    "import os\n",
    "import time\n",
    "import sklearn\n",
    "import scipy\n",
    "import pickle\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_data = pd.read_csv('training_data.csv', index_col=0, infer_datetime_format=True,\n",
    "parse_dates=[0])\n",
    "\n",
    "mms_data[mms_data['selected'] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = mms_data.index\n",
    "selections = mms_data.pop(\"selected\")\n",
    "column_names = mms_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_data = mms_data.replace([np.inf, -np.inf], np.nan)\n",
    "mms_data = mms_data.interpolate(method='time', limit_area='inside')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-corps",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "mms_data = scaler.fit_transform(mms_data)\n",
    "mms_data = pd.DataFrame(mms_data, index, column_names)\n",
    "mms_data = mms_data.join(selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_weight = len(mms_data)/(2*np.bincount(mms_data['selected'].values)[0])\n",
    "true_weight = len(mms_data)/(2*np.bincount(mms_data['selected'].values)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "sitl_windows = mms.mission_events('sroi', mms_data.index[0].to_pydatetime(), mms_data.index[-1].to_pydatetime(), sc='mms1')\n",
    "windows = []\n",
    "for start, end in zip(sitl_windows['tstart'], sitl_windows['tend']):\n",
    "  window = mms_data[start:end]\n",
    "  if not window.empty and len(window[window['selected']==True])>1:\n",
    "    windows.append(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crazy-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "common-delay",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "\n",
    "    sequences = []\n",
    "    for i in range(len(windows)):\n",
    "      X_sequence = []\n",
    "      y_sequence = []\n",
    "\n",
    "      if random.random() < 0.6:\n",
    "        for value in windows[i].values:\n",
    "          X_sequence.append(value[:-1])\n",
    "          y_sequence.append(value[-1])\n",
    "          if len(X_sequence) == SEQ_LEN:\n",
    "            X_train.append(X_sequence.copy())\n",
    "            \n",
    "            y_train.append(y_sequence.copy())\n",
    "\n",
    "            X_sequence = []\n",
    "            y_sequence = []\n",
    "\n",
    "      else:\n",
    "        for value in windows[i].values:\n",
    "          X_sequence.append(value[:-1])\n",
    "          y_sequence.append(value[-1])\n",
    "          if len(X_sequence) == SEQ_LEN:\n",
    "            X_test.append(X_sequence.copy())\n",
    "            \n",
    "            y_test.append(y_sequence.copy())\n",
    "\n",
    "            X_sequence = []\n",
    "            y_sequence = []\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_train = np.expand_dims(np.array(y_train), axis=2)\n",
    "    y_test = np.expand_dims(np.array(y_test), axis=2)\n",
    "\n",
    "    if len(X_train) > len(X_test):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of sequences in training data: {len(X_train)}\")\n",
    "print(f\"Number of sequences in test data: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Credit: Paddy and Kev1n91 from https://stackoverflow.com/a/45305384/3988976)\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Credit: tobigue from https://stackoverflow.com/questions/42158866/neural-network-for-multi-label-classification-with-large-number-of-classes-outpu)\n",
    "def weighted_binary_crossentropy(target, output):\n",
    "    \"\"\"\n",
    "    Weighted binary crossentropy between an output tensor \n",
    "    and a target tensor. POS_WEIGHT is used as a multiplier \n",
    "    for the positive targets.\n",
    "\n",
    "    Combination of the following functions:\n",
    "    * keras.losses.binary_crossentropy\n",
    "    * keras.backend.tensorflow_backend.binary_crossentropy\n",
    "    * tf.nn.weighted_cross_entropy_with_logits\n",
    "    \"\"\"\n",
    "    # transform back to logits\n",
    "    _epsilon = tfb._to_tensor(tfb.epsilon(), output.dtype.base_dtype)\n",
    "    output = tf.clip_by_value(output, _epsilon, 1 - _epsilon)\n",
    "    output = tf.log(output / (1 - output))\n",
    "    # compute weighted loss\n",
    "    loss = tf.nn.weighted_cross_entropy_with_logits(targets=target,\n",
    "                                                    logits=output,\n",
    "                                                    pos_weight=true_weight)\n",
    "    return tf.reduce_mean(loss, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "LAYER_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = f\"{SEQ_LEN}-SEQ_LEN-{BATCH_SIZE}-BATCH_SIZE-{LAYER_SIZE}-LAYER_SIZE-{int(time.time())}\"\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Bidirectional(LSTM(LAYER_SIZE, return_sequences=True), input_shape=(None, X_train.shape[2])))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Bidirectional(LSTM(LAYER_SIZE, return_sequences=True), input_shape=(None, X_train.shape[2])))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(TimeDistributed(Dense(1, activation='sigmoid')))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss=weighted_binary_crossentropy,\n",
    "        optimizer=opt,\n",
    "        metrics=['accuracy', f1, tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"mp-dl-unh\" \n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_f1', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-tradition",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "  x=X_train, y=y_train,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_data=(X_test, y_test),\n",
    "  callbacks=[checkpoint],\n",
    "  verbose=1,\n",
    "  shuffle=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
